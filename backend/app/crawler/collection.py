"""æ”¶è—å¤¹çˆ¬å–æ¨¡å—"""
import time
import re
from typing import Dict, Generator
from selenium.webdriver.common.by import By
from app.utils.logger import logger, get_error_message


class CollectionCrawler:
    """æ”¶è—å¤¹çˆ¬å–å™¨ - è´Ÿè´£ä»æ”¶è—å¤¹è·å–æ¼«ç”»åˆ—è¡¨"""
    
    def __init__(self, browser_manager):
        self.browser = browser_manager
        self.driver = browser_manager.driver
    
    @property
    def base_url(self):
        """åŠ¨æ€è·å–base_urlï¼Œç¡®ä¿è·å–åˆ°æœ€æ–°å€¼"""
        return self.browser.base_url
    
    def get_collection_stream(self) -> Generator[Dict, None, None]:
        """
        è·å–æ”¶è—å¤¹ä¸­çš„æ‰€æœ‰æ¼«ç”»ï¼ˆç”Ÿæˆå™¨ç‰ˆæœ¬ï¼‰
        è¾¹çˆ¬å–è¾¹è¿”å›ï¼Œä¸ç­‰å¾…å…¨éƒ¨å®Œæˆï¼Œå®ç°çœŸæ­£çš„å®æ—¶åŒæ­¥
        
        Yields:
            dict: æ¼«ç”»ä¿¡æ¯å­—å…¸ {'title', 'author', 'manga_url', 'page_count'}
        """
        if not self.driver:
            return
        
        # ç¡®ä¿base_urlå·²è®¾ç½®
        if not self.base_url:
            logger.error("base_urlæœªè®¾ç½®ï¼Œæ— æ³•è·å–æ”¶è—å¤¹")
            return
        
        try:
            manga_urls_set = set()  # ç”¨äºå»é‡
            base = self.base_url.rstrip('/')
            
            # æ­£ç¡®çš„ä¹¦æ¶URL
            bookshelf_url = f"{base}/users-users_fav.html"
            logger.info(f"è®¿é—®ä¹¦æ¶é¡µé¢: {bookshelf_url}")
            self.driver.get(bookshelf_url)
            time.sleep(5)
            
            # æ£€æŸ¥é¡µé¢æ˜¯å¦æˆåŠŸåŠ è½½
            current_url = self.driver.current_url
            page_title = self.driver.title
            logger.info(f"å½“å‰é¡µé¢URL: {current_url}")
            logger.info(f"é¡µé¢æ ‡é¢˜: {page_title}")
            
            if "404" in page_title.lower() or "404" in self.driver.page_source[:1000].lower():
                logger.warning(f"ä¹¦æ¶é¡µé¢è¿”å›404")
                return
            
            # æŸ¥æ‰¾åˆ†ç±»é“¾æ¥
            category_links = {}
            all_links = self.driver.find_elements(By.CSS_SELECTOR, "a")
            
            for link in all_links:
                href = link.get_attribute('href') or ''
                text = link.text.strip()
                
                if 'users-users_fav-c-' in href and text:
                    if text not in ["å…¨éƒ¨", "ç®¡ç†åˆ†é¡", "æ›¸æ¶", "ä¹¦æ¶", "æˆ‘çš„æ›¸æ¶"]:
                        category_links[text] = href
                        logger.info(f"æ‰¾åˆ°åˆ†ç±»: {text} -> {href}")
            
            logger.info(f"å…±æ‰¾åˆ° {len(category_links)} ä¸ªä½œè€…åˆ†ç±»\n")
            
            total_count = 0
            
            # å¦‚æœæœ‰åˆ†ç±»ï¼ŒæŒ‰åˆ†ç±»è·å–æ¼«ç”»
            if category_links:
                for author_idx, (author, category_url) in enumerate(category_links.items(), 1):
                    logger.info(f"[{author_idx}/{len(category_links)}] å¤„ç†ä½œè€…åˆ†ç±»: {author}")
                    
                    # æå–åˆ†ç±»ID
                    category_id_match = re.search(r'users-users_fav-c-(\d+)\.html', category_url)
                    if not category_id_match:
                        logger.warning(f"  æ— æ³•æå–åˆ†ç±»IDï¼Œè·³è¿‡")
                        continue
                    
                    category_id = category_id_match.group(1)
                    page_num = 1
                    author_manga_count = 0
                    
                    current_url = category_url
                    visited_urls = set()
                    
                    # éå†æ‰€æœ‰åˆ†é¡µ
                    # ğŸ”¥ å…³é”®æ”¹è¿›ï¼šå…ˆç¼“å­˜ä¸‹ä¸€é¡µé“¾æ¥ï¼Œå†éå†å½“å‰é¡µï¼Œé¿å…stale element reference
                    next_page_url = None  # ç¼“å­˜çš„ä¸‹ä¸€é¡µé“¾æ¥
                    
                    while True:
                        if current_url in visited_urls:
                            logger.info(f"  æ£€æµ‹åˆ°é‡å¤URLï¼Œåœæ­¢ç¿»é¡µ")
                            break
                        
                        logger.info(f"  è®¿é—®ç¬¬ {page_num} é¡µ: {current_url}")
                        self.driver.get(current_url)
                        visited_urls.add(current_url)
                        time.sleep(2)
                        
                        # ğŸ”¥ ç¬¬ä¸€æ­¥ï¼šç«‹å³æŸ¥æ‰¾å¹¶ç¼“å­˜ä¸‹ä¸€é¡µé“¾æ¥ï¼ˆåœ¨éå†æ¼«ç”»ä¹‹å‰ï¼‰
                        if not next_page_url:  # å¦‚æœè¿˜æ²¡æœ‰ç¼“å­˜ä¸‹ä¸€é¡µé“¾æ¥ï¼Œç°åœ¨æŸ¥æ‰¾
                            logger.debug(f"    æŸ¥æ‰¾ä¸‹ä¸€é¡µé“¾æ¥...")
                            
                            try:
                                # æ ¹æ®MCPç¡®è®¤çš„ç»“æ„ï¼šåˆ†é¡µå™¨æœ‰class "paginator"
                                paginator = self.driver.find_element(By.CSS_SELECTOR, ".paginator")
                                logger.debug(f"    âœ“ æ‰¾åˆ°åˆ†é¡µå™¨å…ƒç´  (class: paginator)")
                                
                                # ğŸ”¥ åªä½¿ç”¨ ".next > a"ï¼ˆ"å¾Œé >"é“¾æ¥ï¼‰æ¥è·å–ä¸‹ä¸€é¡µ
                                try:
                                    next_span = paginator.find_element(By.CSS_SELECTOR, ".next")
                                    if next_span:
                                        next_link = next_span.find_element(By.CSS_SELECTOR, "a")
                                        if next_link:
                                            href = next_link.get_attribute('href')
                                            if href:
                                                # å¤„ç†ç›¸å¯¹è·¯å¾„
                                                if not self.base_url:
                                                    logger.error("base_urlæœªè®¾ç½®ï¼Œæ— æ³•å¤„ç†ä¸‹ä¸€é¡µé“¾æ¥")
                                                else:
                                                    if href.startswith('/'):
                                                        base = self.base_url.rstrip('/')
                                                        full_url = f"{base}{href}"
                                                    elif not href.startswith('http'):
                                                        base = self.base_url.rstrip('/')
                                                        full_url = f"{base}/{href}"
                                                    else:
                                                        full_url = href
                                                    
                                                    # éªŒè¯URLæ˜¯å¦ç¬¦åˆæ¡ä»¶
                                                    if ('users-users_fav' in full_url and 
                                                        '-page-' in full_url and 
                                                        f'c-{category_id}' in full_url and
                                                        full_url not in visited_urls):
                                                        next_page_url = full_url
                                                        logger.info(f"    âœ“ é€šè¿‡'.next > a'æ‰¾åˆ°ä¸‹ä¸€é¡µ: {next_page_url[:80]}")
                                                    else:
                                                        logger.debug(f"    '.next > a'é“¾æ¥ä¸ç¬¦åˆæ¡ä»¶æˆ–å·²è®¿é—®: {full_url[:80]}")
                                            else:
                                                logger.debug(f"    '.next > a'é“¾æ¥æ²¡æœ‰hrefå±æ€§")
                                        else:
                                            logger.debug(f"    '.next'å†…æœªæ‰¾åˆ°<a>æ ‡ç­¾")
                                    else:
                                        logger.debug(f"    æœªæ‰¾åˆ°'.next'å…ƒç´ ")
                                except Exception as e:
                                    logger.debug(f"    æœªæ‰¾åˆ°'.next > a'é“¾æ¥: {get_error_message(e)}")
                                
                                if not next_page_url:
                                    logger.info(f"    âš ï¸  æœªæ‰¾åˆ°'.next > a'é“¾æ¥ï¼Œè¿™æ˜¯æœ€åä¸€é¡µï¼Œéå†å®Œå½“å‰é¡µåå°†ç»“æŸ")
                            except Exception as e:
                                logger.warning(f"    æŸ¥æ‰¾åˆ†é¡µå™¨å¤±è´¥: {get_error_message(e)}")
                                pass
                        
                        # ğŸ”¥ ç¬¬äºŒæ­¥ï¼šéå†å½“å‰é¡µé¢çš„æ¼«ç”»ï¼ˆæ­¤æ—¶ä¸‹ä¸€é¡µé“¾æ¥å·²ç¼“å­˜ï¼‰
                        manga_links = self.driver.find_elements(By.CSS_SELECTOR, "a[href*='photos-index-aid-']")
                        logger.info(f"    ğŸ” CSSæ‰¾åˆ° {len(manga_links)} ä¸ªé“¾æ¥")
                        
                        # ç«‹å³æå–æ‰€æœ‰é“¾æ¥ä¿¡æ¯ï¼Œé¿å…stale element reference
                        manga_info_list = []
                        for manga_link in manga_links:
                            try:
                                manga_url = manga_link.get_attribute('href')
                                title = manga_link.text.strip()
                                
                                # å°è¯•è·å–é¡µæ•°ä¿¡æ¯ï¼ˆä½¿ç”¨classåç§°ï¼Œé¿å…æ±‰å­—å­—ç¬¦ä¸²ï¼‰
                                page_count = None
                                try:
                                    # æŸ¥æ‰¾åŒ…å«æ¼«ç”»é“¾æ¥çš„çˆ¶å®¹å™¨ï¼Œç„¶åæŸ¥æ‰¾ p.l_detla å…ƒç´ 
                                    parent_container = manga_link.find_element(By.XPATH, "./ancestor::*[contains(@class, 'u_listcon') or contains(@class, 'box_cel')]")
                                    page_elem = parent_container.find_element(By.CSS_SELECTOR, "p.l_detla")
                                    if page_elem:
                                        page_text = page_elem.text
                                        # ä»æ–‡æœ¬ä¸­æå–æ•°å­—ï¼ˆæ ¼å¼ï¼šé æ•¸ï¼š20 æˆ– é æ•¸ï¼š20Pï¼‰
                                        page_match = re.search(r'(\d+)\s*P?', page_text)
                                        if page_match:
                                            page_count = int(page_match.group(1))
                                except:
                                    pass
                                
                                if manga_url and title:
                                    manga_info_list.append({
                                        'url': manga_url,
                                        'title': title,
                                        'page_count': page_count
                                    })
                            except Exception as e:
                                # å¦‚æœè·å–ä¿¡æ¯å¤±è´¥ï¼Œè·³è¿‡è¿™ä¸ªé“¾æ¥
                                continue
                        
                        # å¤„ç†æå–çš„ä¿¡æ¯åˆ—è¡¨
                        page_manga_count = 0
                        empty_count = 0
                        dup_count = 0
                        
                        for idx, manga_info in enumerate(manga_info_list, 1):
                            try:
                                manga_url = manga_info['url']
                                title = manga_info['title']
                                page_count = manga_info.get('page_count')
                                
                                if not title or not manga_url:
                                    empty_count += 1
                                    continue
                                
                                # å»é‡
                                if manga_url in manga_urls_set:
                                    dup_count += 1
                                    continue
                                
                                # âœ¨ å…³é”®ï¼šç«‹å³ yieldï¼Œä¸ç­‰å¾…åç»­çˆ¬å–
                                manga_urls_set.add(manga_url)
                                page_manga_count += 1
                                author_manga_count += 1
                                total_count += 1
                                
                                yield {
                                    'title': title,
                                    'author': author,
                                    'manga_url': manga_url,
                                    'page_count': page_count
                                }
                                
                            except Exception as e:
                                logger.warning(f"    å¤„ç†æ¼«ç”»å¤±è´¥: {get_error_message(e)}")
                                continue
                        
                        logger.info(f"    ç¬¬ {page_num} é¡µï¼šæ‰¾åˆ° {page_manga_count} ä¸ªæ¼«ç”»ï¼ˆæ€»è®¡: {total_count}ï¼‰")
                        logger.debug(f"    ğŸ“Š è·³è¿‡ï¼šç©ºæ ‡é¢˜/URL={empty_count}, é‡å¤={dup_count}")
                        
                        if page_manga_count == 0:
                            logger.info(f"    ç¬¬ {page_num} é¡µæ²¡æœ‰æ‰¾åˆ°æ¼«ç”»ï¼Œåœæ­¢ç¿»é¡µ")
                            break
                        
                        # ğŸ”¥ ç¬¬ä¸‰æ­¥ï¼šæ£€æŸ¥æ˜¯å¦æœ‰ä¸‹ä¸€é¡µé“¾æ¥
                        # å¦‚æœæ‰¾ä¸åˆ°'.next > a'é“¾æ¥ï¼Œè¯´æ˜å·²ç»åˆ°æœ€åä¸€é¡µï¼Œéå†å®Œå½“å‰é¡µåç»“æŸï¼Œç»§ç»­ä¸‹ä¸€ä¸ªä½œè€…
                        if not next_page_url:
                            logger.info(f"    âœ“ å·²åˆ°æœ€åä¸€é¡µï¼ˆæœªæ‰¾åˆ°'.next > a'é“¾æ¥ï¼‰ï¼Œç»“æŸå½“å‰ä½œè€…ï¼Œç»§ç»­ä¸‹ä¸€ä¸ªä½œè€…")
                            break
                        
                        # ä¿å­˜å½“å‰ç¼“å­˜çš„ä¸‹ä¸€é¡µé“¾æ¥
                        current_url = next_page_url
                        next_page_url = None  # æ¸…ç©ºç¼“å­˜ï¼Œå‡†å¤‡æŸ¥æ‰¾æ–°çš„ä¸‹ä¸€é¡µ
                        
                        if not current_url:
                            logger.warning(f"    ä¸‹ä¸€é¡µé“¾æ¥æ— æ•ˆï¼Œåœæ­¢ç¿»é¡µ")
                            break
                        
                        page_num += 1
                        
                        if page_num > 100:
                            logger.warning(f"    å·²è¾¾åˆ°æœ€å¤§é¡µæ•°é™åˆ¶(100é¡µ)ï¼Œåœæ­¢ç¿»é¡µ")
                            break
                    
                    logger.info(f"  {author} æ€»å…±è·å– {author_manga_count} ä¸ªæ¼«ç”»\n")
            else:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆ†ç±»é“¾æ¥ï¼Œç›´æ¥ä»å½“å‰é¡µé¢è·å–æ‰€æœ‰æ¼«ç”»
                logger.info("æœªæ‰¾åˆ°åˆ†ç±»é“¾æ¥ï¼Œä»å½“å‰é¡µé¢ç›´æ¥è·å–æ¼«ç”»...")
                manga_links = self.driver.find_elements(By.CSS_SELECTOR, "a[href*='photos-index-aid-']")
                logger.info(f"æ‰¾åˆ° {len(manga_links)} ä¸ªæ¼«ç”»é“¾æ¥")
                
                for manga_link in manga_links:
                    try:
                        manga_url = manga_link.get_attribute('href')
                        title = manga_link.text.strip()
                        
                        if title and manga_url and manga_url not in manga_urls_set:
                            author = "æœªçŸ¥"
                            try:
                                parent = manga_link.find_element(By.XPATH, "./ancestor::*[position()<=5]")
                                author_elem = parent.find_elements(By.XPATH, ".//*[contains(@href, 'users-users_fav-c-')]")
                                if author_elem:
                                    author = author_elem[0].text.strip() or "æœªçŸ¥"
                            except:
                                pass
                            
                            page_count = None
                            try:
                                # æŸ¥æ‰¾åŒ…å«æ¼«ç”»é“¾æ¥çš„çˆ¶å®¹å™¨ï¼Œç„¶åæŸ¥æ‰¾ p.l_detla å…ƒç´ 
                                parent_container = manga_link.find_element(By.XPATH, "./ancestor::*[contains(@class, 'u_listcon') or contains(@class, 'box_cel')]")
                                page_elem = parent_container.find_element(By.CSS_SELECTOR, "p.l_detla")
                                if page_elem:
                                    page_text = page_elem.text
                                    # ä»æ–‡æœ¬ä¸­æå–æ•°å­—ï¼ˆæ ¼å¼ï¼šé æ•¸ï¼š20 æˆ– é æ•¸ï¼š20Pï¼‰
                                    page_match = re.search(r'(\d+)\s*P?', page_text)
                                    if page_match:
                                        page_count = int(page_match.group(1))
                            except:
                                pass
                            
                            manga_urls_set.add(manga_url)
                            total_count += 1
                            
                            yield {
                                'title': title,
                                'author': author,
                                'manga_url': manga_url,
                                'page_count': page_count
                            }
                    except Exception as e:
                        logger.warning(f"å¤„ç†æ¼«ç”»å¤±è´¥: {get_error_message(e)}")
                        continue
            
            logger.info(f"\nâœ“ æ”¶è—å¤¹çˆ¬å–å®Œæˆï¼Œæ€»å…± {total_count} ä¸ªæ¼«ç”»")
            
        except Exception as e:
            logger.error(f"è·å–æ”¶è—å¤¹å¤±è´¥: {get_error_message(e)}")
            return

