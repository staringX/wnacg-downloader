from fastapi import APIRouter, Depends, HTTPException, BackgroundTasks
from sqlalchemy.orm import Session
from typing import List
from datetime import datetime
from pydantic import BaseModel
import os
import time
import uuid
from app.database import get_db

# å¯é€‰çš„Seleniumå¯¼å…¥
try:
    from selenium.webdriver.common.by import By
    SELENIUM_AVAILABLE = True
except ImportError:
    SELENIUM_AVAILABLE = False
    print("è­¦å‘Š: Seleniumæœªå®‰è£…ï¼Œçˆ¬è™«åŠŸèƒ½å°†ä¸å¯ç”¨")
from app.models import Manga
from app.schemas import (
    MangaResponse, SyncResponse, DownloadResponse, 
    BatchDownloadResponse, MangaUpdate
)
from app.crawler.base import MangaCrawler
from app.utils.downloader import MangaDownloader
from app.config import settings
from app.utils.logger import logger

router = APIRouter(prefix="/api", tags=["manga"])


@router.get("/mangas", response_model=List[MangaResponse])
def get_mangas(db: Session = Depends(get_db)):
    """è·å–æ‰€æœ‰æ¼«ç”»"""
    mangas = db.query(Manga).all()
    return [MangaResponse.from_orm(manga) for manga in mangas]


def verify_local_files(db: Session):
    """
    éªŒè¯æœ¬åœ°æ–‡ä»¶ä¸æ•°æ®åº“çŠ¶æ€çš„ä¸€è‡´æ€§
    æ£€æŸ¥æ ‡è®°ä¸º"å·²ä¸‹è½½"çš„æ¼«ç”»ï¼Œå…¶CBZæ–‡ä»¶æ˜¯å¦çœŸå®å­˜åœ¨
    
    Returns:
        tuple: (verified_count, fixed_count, missing_files)
    """
    logger.info("=" * 60)
    logger.info("å¼€å§‹éªŒè¯æœ¬åœ°æ–‡ä»¶å®Œæ•´æ€§...")
    logger.info("=" * 60)
    
    from pathlib import Path
    
    # æŸ¥è¯¢æ‰€æœ‰æ ‡è®°ä¸ºå·²ä¸‹è½½çš„æ¼«ç”»
    downloaded_mangas = db.query(Manga).filter(
        Manga.is_downloaded == True
    ).all()
    
    if not downloaded_mangas:
        logger.info("æ²¡æœ‰å·²ä¸‹è½½çš„æ¼«ç”»éœ€è¦éªŒè¯")
        return 0, 0, []
    
    logger.info(f"æ‰¾åˆ° {len(downloaded_mangas)} ä¸ªå·²ä¸‹è½½çš„æ¼«ç”»è®°å½•")
    
    verified_count = 0
    fixed_count = 0
    missing_files = []
    
    for manga in downloaded_mangas:
        cbz_path = manga.cbz_file_path
        cover_path = manga.cover_image_path
        
        cbz_exists = False
        cover_exists = False
        
        # æ£€æŸ¥CBZæ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if cbz_path:
            cbz_file = Path(cbz_path)
            cbz_exists = cbz_file.exists() and cbz_file.is_file()
        
        # æ£€æŸ¥å°é¢æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if cover_path:
            cover_file = Path(cover_path)
            cover_exists = cover_file.exists() and cover_file.is_file()
        
        # å¦‚æœCBZæ–‡ä»¶ä¸å­˜åœ¨ï¼Œé‡ç½®ä¸‹è½½çŠ¶æ€
        if not cbz_exists:
            logger.warning(f"æ–‡ä»¶ä¸¢å¤±: {manga.title[:50]} - è·¯å¾„: {cbz_path}")
            
            # é‡ç½®ä¸‹è½½çŠ¶æ€
            manga.is_downloaded = False
            manga.download_status = "not_started"
            manga.downloaded_pages = 0
            manga.cbz_file_path = None
            manga.downloaded_at = None
            manga.file_size = None
            
            # å¦‚æœå°é¢ä¹Ÿä¸å­˜åœ¨ï¼Œæ¸…é™¤å°é¢è·¯å¾„
            if not cover_exists:
                manga.cover_image_path = None
            
            fixed_count += 1
            missing_files.append(manga.title)
        else:
            verified_count += 1
            logger.debug(f"éªŒè¯é€šè¿‡: {manga.title[:50]}")
    
    # æäº¤æ‰€æœ‰æ›´æ”¹
    if fixed_count > 0:
        db.commit()
        logger.warning(f"å·²é‡ç½® {fixed_count} ä¸ªä¸¢å¤±æ–‡ä»¶çš„ä¸‹è½½çŠ¶æ€")
    
    logger.info("=" * 60)
    logger.info(f"éªŒè¯å®Œæˆ: {verified_count} ä¸ªå®Œæ•´, {fixed_count} ä¸ªéœ€è¦é‡æ–°ä¸‹è½½")
    logger.info("=" * 60)
    
    return verified_count, fixed_count, missing_files


class VerifyResponse(BaseModel):
    success: bool
    message: str
    verified_count: int
    fixed_count: int
    missing_files: List[str]


@router.post("/verify-files", response_model=VerifyResponse)
def verify_files(db: Session = Depends(get_db)):
    """
    æ‰‹åŠ¨éªŒè¯æœ¬åœ°æ–‡ä»¶å®Œæ•´æ€§
    
    æ£€æŸ¥æ‰€æœ‰æ ‡è®°ä¸º"å·²ä¸‹è½½"çš„æ¼«ç”»ï¼ŒéªŒè¯å…¶CBZæ–‡ä»¶æ˜¯å¦çœŸå®å­˜åœ¨ã€‚
    å¦‚æœæ–‡ä»¶ä¸¢å¤±ï¼Œè‡ªåŠ¨é‡ç½®ä¸‹è½½çŠ¶æ€ï¼Œå…è®¸é‡æ–°ä¸‹è½½ã€‚
    
    è¿”å›ï¼š
    - verified_count: éªŒè¯é€šè¿‡çš„æ•°é‡
    - fixed_count: å·²ä¿®å¤ï¼ˆé‡ç½®ï¼‰çš„æ•°é‡
    - missing_files: ä¸¢å¤±æ–‡ä»¶çš„æ¼«ç”»æ ‡é¢˜åˆ—è¡¨
    """
    try:
        verified_count, fixed_count, missing_files = verify_local_files(db)
        
        if fixed_count > 0:
            message = f"å‘ç° {fixed_count} ä¸ªæ–‡ä»¶ä¸¢å¤±ï¼Œå·²é‡ç½®ä¸‹è½½çŠ¶æ€ã€‚{verified_count} ä¸ªæ–‡ä»¶å®Œæ•´ã€‚"
        else:
            message = f"æ‰€æœ‰ {verified_count} ä¸ªå·²ä¸‹è½½æ¼«ç”»çš„æ–‡ä»¶éƒ½å®Œæ•´ã€‚"
        
        return VerifyResponse(
            success=True,
            message=message,
            verified_count=verified_count,
            fixed_count=fixed_count,
            missing_files=missing_files
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æ–‡ä»¶éªŒè¯å¤±è´¥: {str(e)}")


@router.post("/sync", response_model=SyncResponse)
def sync_collection(background_tasks: BackgroundTasks, db: Session = Depends(get_db)):
    """åŒæ­¥æ”¶è—å¤¹"""
    if not SELENIUM_AVAILABLE:
        raise HTTPException(status_code=503, detail="Seleniumæœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨çˆ¬è™«åŠŸèƒ½")
    
    # ğŸ” ç¬¬ä¸€æ­¥ï¼šéªŒè¯æœ¬åœ°æ–‡ä»¶å®Œæ•´æ€§
    try:
        verified_count, fixed_count, missing_files = verify_local_files(db)
    except Exception as e:
        logger.warning(f"æ–‡ä»¶éªŒè¯å¤±è´¥: {e}")
        # éªŒè¯å¤±è´¥ä¸å½±å“åŒæ­¥ï¼Œç»§ç»­æ‰§è¡Œ
    
    crawler = MangaCrawler()
    
    try:
        # ç™»å½•
        if not crawler.login(settings.manga_username, settings.manga_password):
            raise HTTPException(status_code=401, detail="ç™»å½•å¤±è´¥")
        
        # ğŸš€ ä½¿ç”¨ç”Ÿæˆå™¨ï¼šè¾¹çˆ¬å–è¾¹ä¿å­˜ï¼ŒçœŸæ­£çš„å®æ—¶åŒæ­¥ï¼
        logger.info("=" * 60)
        logger.info("å¼€å§‹å®æ—¶åŒæ­¥ï¼ˆç”Ÿæˆå™¨æ¨¡å¼ï¼‰")
        logger.info("æç¤ºï¼šæ¯çˆ¬å–åˆ°ä¸€ä¸ªæ¼«ç”»å°±ä¼šç«‹å³ä¿å­˜ï¼Œåˆ·æ–°é¡µé¢å³å¯çœ‹åˆ°æœ€æ–°æ•°æ®")
        logger.info("=" * 60)
        
        added_count = 0
        updated_count = 0
        processed_count = 0
        
        # ç”Ÿæˆå™¨ï¼šæ¯yieldä¸€ä¸ªæ¼«ç”»ï¼Œç«‹å³å¤„ç†å¹¶ä¿å­˜
        for item in crawler.get_collection_stream():
            processed_count += 1
            
            try:
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                existing = db.query(Manga).filter(Manga.manga_url == item['manga_url']).first()
                
                if existing:
                    # å·²å­˜åœ¨ï¼Œä»…æ›´æ–°åŸºæœ¬ä¿¡æ¯ï¼ˆå¦‚æœéœ€è¦ï¼‰
                    if item.get('page_count') and not existing.page_count:
                        existing.page_count = item['page_count']
                        db.commit()
                    updated_count += 1
                    logger.info(f"[{processed_count}] âŸ³ å·²å­˜åœ¨: {item['title'][:50]}")
                else:
                    # æ–°æ¼«ç”»ï¼Œåˆ›å»ºè®°å½•å¹¶ç«‹å³ä¿å­˜
                    logger.info(f"[{processed_count}] âœš æ–°å¢: {item['title'][:50]}")
                    
                    manga = Manga(
                        title=item['title'],
                        author=item['author'],
                        manga_url=item['manga_url'],
                        page_count=item.get('page_count')
                    )
                    db.add(manga)
                    db.commit()  # ğŸ”¥ ç«‹å³æäº¤ï¼ç”¨æˆ·åˆ·æ–°é¡µé¢å°±èƒ½çœ‹åˆ°
                    db.refresh(manga)  # åˆ·æ–°å¯¹è±¡ä»¥è·å–ID
                    
                    added_count += 1
                    
                    # ç«‹å³è·å–è¯¦ç»†ä¿¡æ¯ï¼ˆé¡µæ•°ã€æ›´æ–°æ—¥æœŸã€å°é¢ï¼‰
                    try:
                        details = crawler.get_manga_details(manga.manga_url)
                        
                        if details:
                            # æ›´æ–°è¯¦ç»†ä¿¡æ¯
                            if details.get('page_count'):
                                manga.page_count = details['page_count']
                            if details.get('updated_at'):
                                manga.updated_at = details['updated_at']
                            if details.get('cover_image_url'):
                                manga.cover_image_url = details['cover_image_url']
                            db.commit()  # ğŸ”¥ å†æ¬¡æäº¤è¯¦æƒ…ï¼
                            logger.debug(f"     âœ“ è¯¦æƒ…: é¡µæ•°={manga.page_count}, æ›´æ–°={str(manga.updated_at)[:10] if manga.updated_at else 'N/A'}")
                        else:
                            logger.warning(f"     âš  æ— æ³•è·å–è¯¦ç»†ä¿¡æ¯: {manga.title[:30]}")
                            
                    except Exception as detail_error:
                        logger.warning(f"     âš  è·å–è¯¦æƒ…å¤±è´¥: {detail_error}")
                        # è¯¦æƒ…è·å–å¤±è´¥ä¸å½±å“åŸºæœ¬è®°å½•çš„ä¿å­˜ï¼Œç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ª
                    
            except Exception as e:
                logger.error(f"[{processed_count}] âœ— å¤„ç†å¤±è´¥: {item.get('title', 'Unknown')[:50]} - {e}")
                db.rollback()  # å›æ»šå½“å‰å¤±è´¥çš„äº‹åŠ¡
                continue
        
        logger.info(f"åŒæ­¥å®Œæˆï¼šæ–°å¢ {added_count} ä¸ªï¼Œæ›´æ–° {updated_count} ä¸ª")
        
        return SyncResponse(
            success=True,
            message=f"åŒæ­¥å®Œæˆï¼šæ–°å¢ {added_count} ä¸ªï¼Œæ›´æ–° {updated_count} ä¸ª",
            added_count=added_count,
            updated_count=updated_count
        )
    except Exception as e:
        db.rollback()
        raise HTTPException(status_code=500, detail=str(e))
    finally:
        crawler.close()


@router.post("/download/{manga_id}", response_model=DownloadResponse)
def download_manga(manga_id: str, background_tasks: BackgroundTasks, db: Session = Depends(get_db)):
    """
    ä¸‹è½½å•ä¸ªæ¼«ç”»ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰
    
    åŠŸèƒ½ï¼š
    - å¦‚æœå·²å®Œå…¨ä¸‹è½½ï¼Œç›´æ¥è¿”å›
    - å¦‚æœä¸‹è½½ä¸­æ–­ï¼Œè‡ªåŠ¨æ¢å¤ï¼ˆè·³è¿‡å·²ä¸‹è½½çš„é¡µï¼‰
    - è¾¹ä¸‹è½½è¾¹ä¿å­˜ï¼Œå®æ—¶æ›´æ–°è¿›åº¦
    """
    manga = db.query(Manga).filter(Manga.id == manga_id).first()
    if not manga:
        raise HTTPException(status_code=404, detail="æ¼«ç”»ä¸å­˜åœ¨")
    
    # æ£€æŸ¥æ˜¯å¦å·²å®Œå…¨ä¸‹è½½
    if manga.download_status == "completed" and manga.is_downloaded:
        return DownloadResponse(
            success=True,
            message="æ¼«ç”»å·²ä¸‹è½½",
            manga_id=manga_id,
            file_path=manga.cbz_file_path
        )
    
    crawler = MangaCrawler()
    downloader = MangaDownloader()
    
    try:
        # ç™»å½•
        if not crawler.login(settings.manga_username, settings.manga_password):
            raise HTTPException(status_code=401, detail="ç™»å½•å¤±è´¥")
        
        # æ ‡è®°ä¸ºä¸‹è½½ä¸­
        manga.download_status = "downloading"
        manga.downloaded_pages = manga.downloaded_pages or 0
        db.commit()
        
        print(f"\n{'='*60}")
        print(f"å¼€å§‹ä¸‹è½½: {manga.title}")
        if manga.downloaded_pages > 0:
            print(f"æ–­ç‚¹ç»­ä¼ : å·²ä¸‹è½½ {manga.downloaded_pages} é¡µ")
        print(f"{'='*60}\n")
        
        # è·å–æ¼«ç”»è¯¦æƒ…ï¼ˆå¦‚æœç¼ºå¤±ï¼‰
        if not manga.page_count or not manga.cover_image_url:
            details = crawler.get_manga_details(manga.manga_url)
            if details:
                if details.get('page_count'):
                    manga.page_count = details['page_count']
                if details.get('updated_at'):
                    manga.updated_at = details['updated_at']
                if details.get('cover_image_url'):
                    manga.cover_image_url = details['cover_image_url']
                db.commit()
        
        # è·å–å›¾ç‰‡åˆ—è¡¨
        images = crawler.get_manga_images(manga.manga_url)
        
        if not images:
            manga.download_status = "failed"
            db.commit()
            raise HTTPException(status_code=500, detail="æ— æ³•è·å–å›¾ç‰‡åˆ—è¡¨")
        
        # ğŸ”¥ ä½¿ç”¨ç”Ÿæˆå™¨ä¸‹è½½ï¼šè¾¹ä¸‹è½½è¾¹ä¿å­˜ï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ 
        cbz_path = None
        cover_path = None
        
        for progress in downloader.download_manga_stream(manga.title, images, resume=True):
            status = progress.get('status')
            
            # æ›´æ–°ä¸‹è½½è¿›åº¦
            if 'downloaded_count' in progress:
                manga.downloaded_pages = progress['downloaded_count']
                db.commit()  # ğŸ”¥ å®æ—¶ä¿å­˜è¿›åº¦ï¼
            
            # ä¸‹è½½å®Œæˆ
            if status == 'completed':
                cbz_path = progress.get('cbz_path')
                cover_path = progress.get('cover_path')
                file_size = progress.get('file_size', 0)
                
                # æ›´æ–°æ•°æ®åº“
                manga.is_downloaded = True
                manga.download_status = "completed"
                manga.downloaded_at = datetime.now()
                manga.cbz_file_path = cbz_path
                manga.cover_image_path = cover_path
                manga.file_size = file_size
                manga.downloaded_pages = len(images)
                db.commit()
                
                print(f"\n{'='*60}")
                print(f"âœ… ä¸‹è½½å®Œæˆ: {manga.title}")
                print(f"æ–‡ä»¶å¤§å°: {file_size / 1024 / 1024:.2f} MB")
                print(f"{'='*60}\n")
            
            # ä¸‹è½½å¤±è´¥
            elif status == 'error':
                manga.download_status = "failed"
                db.commit()
                raise HTTPException(status_code=500, detail=progress.get('message', 'ä¸‹è½½å¤±è´¥'))
        
        if not cbz_path:
            manga.download_status = "failed"
            db.commit()
            raise HTTPException(status_code=500, detail="ä¸‹è½½å¤±è´¥")
        
        return DownloadResponse(
            success=True,
            message="ä¸‹è½½æˆåŠŸ",
            manga_id=manga_id,
            file_path=cbz_path
        )
    except Exception as e:
        manga.download_status = "failed"
        db.commit()
        raise HTTPException(status_code=500, detail=str(e))
    finally:
        crawler.close()


class BatchDownloadRequest(BaseModel):
    manga_ids: List[str]


@router.post("/download/batch", response_model=BatchDownloadResponse)
def download_batch(request: BatchDownloadRequest, background_tasks: BackgroundTasks, db: Session = Depends(get_db)):
    """
    æ‰¹é‡ä¸‹è½½æ¼«ç”»ï¼ˆé€ä¸ªå¤„ç†ï¼Œå®æ—¶ä¿å­˜ï¼‰
    
    åŠŸèƒ½ï¼š
    - æ¯ä¸‹è½½å®Œä¸€æœ¬ï¼Œç«‹å³ä¿å­˜æ•°æ®åº“
    - ä¸­é€”ä¸­æ–­ä¸å½±å“å·²ä¸‹è½½çš„æ¼«ç”»
    - æ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼ˆæ¯æœ¬æ¼«ç”»ç‹¬ç«‹ï¼‰
    """
    success_count = 0
    failed_count = 0
    failed_titles = []
    
    print(f"\n{'='*60}")
    print(f"å¼€å§‹æ‰¹é‡ä¸‹è½½: {len(request.manga_ids)} æœ¬æ¼«ç”»")
    print(f"{'='*60}\n")
    
    # é€ä¸ªä¸‹è½½ï¼Œæ¯å®Œæˆä¸€ä¸ªç«‹å³ä¿å­˜
    for idx, manga_id in enumerate(request.manga_ids, 1):
        try:
            manga = db.query(Manga).filter(Manga.id == manga_id).first()
            if not manga:
                print(f"[{idx}/{len(request.manga_ids)}] âœ— è·³è¿‡: æ¼«ç”»ID {manga_id} ä¸å­˜åœ¨")
                failed_count += 1
                continue
            
            print(f"\n[{idx}/{len(request.manga_ids)}] å¤„ç†: {manga.title}")
            
            # å¦‚æœå·²ç»ä¸‹è½½å®Œæˆï¼Œè·³è¿‡
            if manga.download_status == "completed" and manga.is_downloaded:
                print(f"  â­ï¸  å·²ä¸‹è½½ï¼Œè·³è¿‡")
                success_count += 1
                continue
            
            # è°ƒç”¨å•æœ¬ä¸‹è½½ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰
            try:
                result = download_manga(manga_id, background_tasks, db)
                if result.success:
                    success_count += 1
                    print(f"  âœ… æˆåŠŸ")
                else:
                    failed_count += 1
                    failed_titles.append(manga.title)
                    print(f"  âŒ å¤±è´¥")
            except Exception as e:
                failed_count += 1
                failed_titles.append(manga.title)
                print(f"  âŒ å¤±è´¥: {str(e)}")
                # å•æœ¬å¤±è´¥ä¸å½±å“å…¶ä»–æ¼«ç”»ï¼Œç»§ç»­å¤„ç†ä¸‹ä¸€æœ¬
                continue
                
        except Exception as e:
            print(f"[{idx}/{len(request.manga_ids)}] âœ— å¤„ç†å¤±è´¥: {e}")
            failed_count += 1
            continue
    
    print(f"\n{'='*60}")
    print(f"æ‰¹é‡ä¸‹è½½å®Œæˆ")
    print(f"æˆåŠŸ: {success_count} æœ¬")
    print(f"å¤±è´¥: {failed_count} æœ¬")
    if failed_titles:
        print(f"å¤±è´¥åˆ—è¡¨: {', '.join(failed_titles[:5])}" + ("..." if len(failed_titles) > 5 else ""))
    print(f"{'='*60}\n")
    
    message = f"æ‰¹é‡ä¸‹è½½å®Œæˆï¼šæˆåŠŸ {success_count}ï¼Œå¤±è´¥ {failed_count}"
    if failed_titles and len(failed_titles) <= 3:
        message += f"ã€‚å¤±è´¥: {', '.join(failed_titles)}"
    
    return BatchDownloadResponse(
        success=True,
        message=message,
        total=len(request.manga_ids),
        success_count=success_count,
        failed_count=failed_count
    )


@router.get("/recent-updates", response_model=List[MangaResponse])
def get_recent_updates(db: Session = Depends(get_db)):
    """è·å–æœ€è¿‘æ›´æ–°ï¼ˆæ”¶è—ä½œè€…çš„æœ€è¿‘æ›´æ–°ï¼‰"""
    # è·å–æ‰€æœ‰å·²æ”¶è—çš„ä½œè€…
    authors = db.query(Manga.author).distinct().all()
    author_list = [a[0] for a in authors]
    
    if not author_list:
        return []
    
    # è·å–æ¯ä¸ªä½œè€…æ”¶è—å¤¹ä¸­æœ€æ–°çš„æ¼«ç”»çš„æ›´æ–°æ—¥æœŸ
    author_latest_dates = {}
    for author in author_list:
        latest_manga = db.query(Manga).filter(
            Manga.author == author
        ).order_by(Manga.updated_at.desc()).first()
        
        if latest_manga and latest_manga.updated_at:
            author_latest_dates[author] = latest_manga.updated_at
    
    # æœç´¢æ¯ä¸ªä½œè€…ï¼Œè·å–æ›´æ–°æ—¥æœŸæ™šäºæ”¶è—å¤¹æœ€æ–°æ¼«ç”»çš„æ‰€æœ‰æ¼«ç”»
    crawler = MangaCrawler()
    recent_updates = []
    
    try:
        if not crawler.login(settings.manga_username, settings.manga_password):
            return []
        
        for author in author_list:
            # æœç´¢ä½œè€…
            search_url = f"{crawler.base_url}/search-index.html?keywords={author}"
            crawler.driver.get(search_url)
            time.sleep(2)
            
            # è·å–æœç´¢ç»“æœ
            manga_items = crawler.driver.find_elements(By.CSS_SELECTOR, "a[href*='photos-index']")
            
            for item in manga_items:
                try:
                    manga_url = item.get_attribute('href')
                    if not manga_url:
                        continue
                    
                    # æ£€æŸ¥æ˜¯å¦å·²åœ¨æ”¶è—å¤¹ä¸­
                    existing = db.query(Manga).filter(
                        Manga.manga_url == manga_url
                    ).first()
                    
                    if existing:
                        continue  # å·²åœ¨æ”¶è—å¤¹ä¸­ï¼Œè·³è¿‡
                    
                    details = crawler.get_manga_details(manga_url)
                    
                    if details:
                        latest_date = author_latest_dates.get(author)
                        if latest_date and details.get('updated_at'):
                            if details['updated_at'] > latest_date:
                                # åˆ›å»ºä¸´æ—¶Mangaå¯¹è±¡ç”¨äºè¿”å›
                                temp_manga = Manga(
                                    id=str(uuid.uuid4()),
                                    title=details['title'],
                                    author=author,
                                    manga_url=manga_url,
                                    page_count=details.get('page_count'),
                                    updated_at=details.get('updated_at'),
                                    cover_image_url=details.get('cover_image_url'),
                                    is_downloaded=False
                                )
                                recent_updates.append(temp_manga)
                except Exception as e:
                    print(f"å¤„ç†æœç´¢ç»“æœé¡¹å¤±è´¥: {e}")
                    continue
    except Exception as e:
        print(f"è·å–æœ€è¿‘æ›´æ–°å¤±è´¥: {e}")
    finally:
        crawler.close()
    
    # è½¬æ¢ä¸ºå“åº”æ ¼å¼
    return [MangaResponse.from_orm(manga) for manga in recent_updates]


class AddToCollectionRequest(BaseModel):
    manga_url: str
    author: str


@router.post("/add-to-collection")
def add_to_collection(request: AddToCollectionRequest, db: Session = Depends(get_db)):
    """æ·»åŠ æ¼«ç”»åˆ°æ”¶è—å¤¹ï¼ˆå¯¹åº”ä½œè€…åˆ†ç±»ï¼‰"""
    crawler = MangaCrawler()
    
    try:
        if not crawler.login(settings.manga_username, settings.manga_password):
            raise HTTPException(status_code=401, detail="ç™»å½•å¤±è´¥")
        
        # å¯¼èˆªåˆ°æ¼«ç”»é¡µé¢
        crawler.driver.get(request.manga_url)
        time.sleep(2)
        
        # æŸ¥æ‰¾"åŠ å…¥æ›¸æ¶"æŒ‰é’®
        add_button = crawler.driver.find_element(By.XPATH, "//*[contains(text(), 'åŠ å…¥æ›¸æ¶')]")
        add_button.click()
        time.sleep(1)
        
        # é€‰æ‹©ä½œè€…åˆ†ç±»
        # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…ç½‘ç«™UIæ¥å®ç°
        # å¯èƒ½éœ€è¦æ‰“å¼€ä¸‹æ‹‰èœå•é€‰æ‹©åˆ†ç±»
        
        # æ·»åŠ åˆ°æ•°æ®åº“
        details = crawler.get_manga_details(request.manga_url)
        if details:
            manga = Manga(
                title=details['title'],
                author=request.author,
                manga_url=request.manga_url,
                page_count=details.get('page_count'),
                updated_at=details.get('updated_at'),
                cover_image_url=details.get('cover_image_url')
            )
            db.add(manga)
            db.commit()
            
            return {"success": True, "message": "å·²æ·»åŠ åˆ°æ”¶è—å¤¹"}
        else:
            raise HTTPException(status_code=500, detail="æ— æ³•è·å–æ¼«ç”»è¯¦æƒ…")
    except Exception as e:
        db.rollback()
        raise HTTPException(status_code=500, detail=str(e))
    finally:
        crawler.close()


@router.delete("/manga/{manga_id}")
def delete_manga(manga_id: str, db: Session = Depends(get_db)):
    """åˆ é™¤æ¼«ç”»"""
    manga = db.query(Manga).filter(Manga.id == manga_id).first()
    if not manga:
        raise HTTPException(status_code=404, detail="æ¼«ç”»ä¸å­˜åœ¨")
    
    # åˆ é™¤æ–‡ä»¶
    if manga.cbz_file_path and os.path.exists(manga.cbz_file_path):
        os.remove(manga.cbz_file_path)
    if manga.cover_image_path and os.path.exists(manga.cover_image_path):
        os.remove(manga.cover_image_path)
    
    db.delete(manga)
    db.commit()
    
    return {"success": True, "message": "åˆ é™¤æˆåŠŸ"}
