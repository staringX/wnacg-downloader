"""åŒæ­¥ç›¸å…³è·¯ç”±"""
from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.orm import Session
from pathlib import Path
from pydantic import BaseModel
from typing import List
from app.database import get_db
from app.models import Manga
from app.schemas import SyncResponse
from app.crawler.base import MangaCrawler
from app.config import settings
from app.utils.logger import logger

router = APIRouter(prefix="/api", tags=["sync"])


class VerifyResponse(BaseModel):
    success: bool
    message: str
    verified_count: int
    fixed_count: int
    missing_files: List[str]


def verify_local_files(db: Session):
    """
    éªŒè¯æœ¬åœ°æ–‡ä»¶ä¸æ•°æ®åº“çŠ¶æ€çš„ä¸€è‡´æ€§
    æ£€æŸ¥æ ‡è®°ä¸º"å·²ä¸‹è½½"çš„æ¼«ç”»ï¼Œå…¶CBZæ–‡ä»¶æ˜¯å¦çœŸå®å­˜åœ¨
    
    Returns:
        tuple: (verified_count, fixed_count, missing_files)
    """
    logger.info("=" * 60)
    logger.info("å¼€å§‹éªŒè¯æœ¬åœ°æ–‡ä»¶å®Œæ•´æ€§...")
    logger.info("=" * 60)
    
    # æŸ¥è¯¢æ‰€æœ‰æ ‡è®°ä¸ºå·²ä¸‹è½½çš„æ¼«ç”»
    downloaded_mangas = db.query(Manga).filter(
        Manga.is_downloaded == True
    ).all()
    
    if not downloaded_mangas:
        logger.info("æ²¡æœ‰å·²ä¸‹è½½çš„æ¼«ç”»éœ€è¦éªŒè¯")
        return 0, 0, []
    
    logger.info(f"æ‰¾åˆ° {len(downloaded_mangas)} ä¸ªå·²ä¸‹è½½çš„æ¼«ç”»è®°å½•")
    
    verified_count = 0
    fixed_count = 0
    missing_files = []
    
    for manga in downloaded_mangas:
        cbz_path = manga.cbz_file_path
        cover_path = manga.cover_image_path
        
        cbz_exists = False
        cover_exists = False
        
        # æ£€æŸ¥CBZæ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if cbz_path:
            cbz_file = Path(cbz_path)
            cbz_exists = cbz_file.exists() and cbz_file.is_file()
        
        # æ£€æŸ¥å°é¢æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if cover_path:
            cover_file = Path(cover_path)
            cover_exists = cover_file.exists() and cover_file.is_file()
        
        # å¦‚æœCBZæ–‡ä»¶ä¸å­˜åœ¨ï¼Œé‡ç½®ä¸‹è½½çŠ¶æ€
        if not cbz_exists:
            logger.warning(f"æ–‡ä»¶ä¸¢å¤±: {manga.title[:50]} - è·¯å¾„: {cbz_path}")
            
            # é‡ç½®ä¸‹è½½çŠ¶æ€
            manga.is_downloaded = False
            manga.download_status = "not_started"
            manga.downloaded_pages = 0
            manga.cbz_file_path = None
            manga.downloaded_at = None
            manga.file_size = None
            
            # å¦‚æœå°é¢ä¹Ÿä¸å­˜åœ¨ï¼Œæ¸…é™¤å°é¢è·¯å¾„
            if not cover_exists:
                manga.cover_image_path = None
            
            fixed_count += 1
            missing_files.append(manga.title)
        else:
            verified_count += 1
            logger.debug(f"éªŒè¯é€šè¿‡: {manga.title[:50]}")
    
    # æäº¤æ‰€æœ‰æ›´æ”¹
    if fixed_count > 0:
        db.commit()
        logger.warning(f"å·²é‡ç½® {fixed_count} ä¸ªä¸¢å¤±æ–‡ä»¶çš„ä¸‹è½½çŠ¶æ€")
    
    logger.info("=" * 60)
    logger.info(f"éªŒè¯å®Œæˆ: {verified_count} ä¸ªå®Œæ•´, {fixed_count} ä¸ªéœ€è¦é‡æ–°ä¸‹è½½")
    logger.info("=" * 60)
    
    return verified_count, fixed_count, missing_files


@router.post("/verify-files", response_model=VerifyResponse)
def verify_files(db: Session = Depends(get_db)):
    """
    æ‰‹åŠ¨éªŒè¯æœ¬åœ°æ–‡ä»¶å®Œæ•´æ€§
    
    æ£€æŸ¥æ‰€æœ‰æ ‡è®°ä¸º"å·²ä¸‹è½½"çš„æ¼«ç”»ï¼ŒéªŒè¯å…¶CBZæ–‡ä»¶æ˜¯å¦çœŸå®å­˜åœ¨ã€‚
    å¦‚æœæ–‡ä»¶ä¸¢å¤±ï¼Œè‡ªåŠ¨é‡ç½®ä¸‹è½½çŠ¶æ€ï¼Œå…è®¸é‡æ–°ä¸‹è½½ã€‚
    
    è¿”å›ï¼š
    - verified_count: éªŒè¯é€šè¿‡çš„æ•°é‡
    - fixed_count: å·²ä¿®å¤ï¼ˆé‡ç½®ï¼‰çš„æ•°é‡
    - missing_files: ä¸¢å¤±æ–‡ä»¶çš„æ¼«ç”»æ ‡é¢˜åˆ—è¡¨
    """
    try:
        verified_count, fixed_count, missing_files = verify_local_files(db)
        
        if fixed_count > 0:
            message = f"å‘ç° {fixed_count} ä¸ªæ–‡ä»¶ä¸¢å¤±ï¼Œå·²é‡ç½®ä¸‹è½½çŠ¶æ€ã€‚{verified_count} ä¸ªæ–‡ä»¶å®Œæ•´ã€‚"
        else:
            message = f"æ‰€æœ‰ {verified_count} ä¸ªå·²ä¸‹è½½æ¼«ç”»çš„æ–‡ä»¶éƒ½å®Œæ•´ã€‚"
        
        return VerifyResponse(
            success=True,
            message=message,
            verified_count=verified_count,
            fixed_count=fixed_count,
            missing_files=missing_files
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æ–‡ä»¶éªŒè¯å¤±è´¥: {str(e)}")


@router.post("/sync", response_model=SyncResponse)
def sync_collection(db: Session = Depends(get_db)):
    """åŒæ­¥æ”¶è—å¤¹"""
    try:
        from selenium.webdriver.common.by import By
        SELENIUM_AVAILABLE = True
    except ImportError:
        SELENIUM_AVAILABLE = False
    
    if not SELENIUM_AVAILABLE:
        raise HTTPException(status_code=503, detail="Seleniumæœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨çˆ¬è™«åŠŸèƒ½")
    
    # ğŸ” ç¬¬ä¸€æ­¥ï¼šéªŒè¯æœ¬åœ°æ–‡ä»¶å®Œæ•´æ€§
    try:
        verified_count, fixed_count, missing_files = verify_local_files(db)
    except Exception as e:
        logger.warning(f"æ–‡ä»¶éªŒè¯å¤±è´¥: {e}")
        # éªŒè¯å¤±è´¥ä¸å½±å“åŒæ­¥ï¼Œç»§ç»­æ‰§è¡Œ
    
    crawler = MangaCrawler()
    
    try:
        # ç™»å½•
        if not crawler.login(settings.manga_username, settings.manga_password):
            raise HTTPException(status_code=401, detail="ç™»å½•å¤±è´¥")
        
        # ğŸš€ ä½¿ç”¨ç”Ÿæˆå™¨ï¼šè¾¹çˆ¬å–è¾¹ä¿å­˜ï¼ŒçœŸæ­£çš„å®æ—¶åŒæ­¥ï¼
        logger.info("=" * 60)
        logger.info("å¼€å§‹å®æ—¶åŒæ­¥ï¼ˆç”Ÿæˆå™¨æ¨¡å¼ï¼‰")
        logger.info("æç¤ºï¼šæ¯çˆ¬å–åˆ°ä¸€ä¸ªæ¼«ç”»å°±ä¼šç«‹å³ä¿å­˜ï¼Œåˆ·æ–°é¡µé¢å³å¯çœ‹åˆ°æœ€æ–°æ•°æ®")
        logger.info("=" * 60)
        
        added_count = 0
        updated_count = 0
        processed_count = 0
        
        # ç”Ÿæˆå™¨ï¼šæ¯yieldä¸€ä¸ªæ¼«ç”»ï¼Œç«‹å³å¤„ç†å¹¶ä¿å­˜
        for item in crawler.get_collection_stream():
            processed_count += 1
            
            try:
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                existing = db.query(Manga).filter(Manga.manga_url == item['manga_url']).first()
                
                if existing:
                    # å·²å­˜åœ¨ï¼Œä»…æ›´æ–°åŸºæœ¬ä¿¡æ¯ï¼ˆå¦‚æœéœ€è¦ï¼‰
                    if item.get('page_count') and not existing.page_count:
                        existing.page_count = item['page_count']
                        db.commit()
                    updated_count += 1
                    logger.info(f"[{processed_count}] âŸ³ å·²å­˜åœ¨: {item['title'][:50]}")
                else:
                    # æ–°æ¼«ç”»ï¼Œåˆ›å»ºè®°å½•å¹¶ç«‹å³ä¿å­˜
                    logger.info(f"[{processed_count}] âœš æ–°å¢: {item['title'][:50]}")
                    
                    manga = Manga(
                        title=item['title'],
                        author=item['author'],
                        manga_url=item['manga_url'],
                        page_count=item.get('page_count')
                    )
                    db.add(manga)
                    db.commit()  # ğŸ”¥ ç«‹å³æäº¤ï¼ç”¨æˆ·åˆ·æ–°é¡µé¢å°±èƒ½çœ‹åˆ°
                    db.refresh(manga)  # åˆ·æ–°å¯¹è±¡ä»¥è·å–ID
                    
                    added_count += 1
                    
                    # ç«‹å³è·å–è¯¦ç»†ä¿¡æ¯ï¼ˆé¡µæ•°ã€æ›´æ–°æ—¥æœŸã€å°é¢ï¼‰
                    try:
                        details = crawler.get_manga_details(manga.manga_url)
                        
                        if details:
                            # æ›´æ–°è¯¦ç»†ä¿¡æ¯
                            if details.get('page_count'):
                                manga.page_count = details['page_count']
                            if details.get('updated_at'):
                                manga.updated_at = details['updated_at']
                            if details.get('cover_image_url'):
                                manga.cover_image_url = details['cover_image_url']
                            db.commit()  # ğŸ”¥ å†æ¬¡æäº¤è¯¦æƒ…ï¼
                            logger.debug(f"     âœ“ è¯¦æƒ…: é¡µæ•°={manga.page_count}, æ›´æ–°={str(manga.updated_at)[:10] if manga.updated_at else 'N/A'}")
                        else:
                            logger.warning(f"     âš  æ— æ³•è·å–è¯¦ç»†ä¿¡æ¯: {manga.title[:30]}")
                            
                    except Exception as detail_error:
                        logger.warning(f"     âš  è·å–è¯¦æƒ…å¤±è´¥: {detail_error}")
                        # è¯¦æƒ…è·å–å¤±è´¥ä¸å½±å“åŸºæœ¬è®°å½•çš„ä¿å­˜ï¼Œç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ª
                    
            except Exception as e:
                logger.error(f"[{processed_count}] âœ— å¤„ç†å¤±è´¥: {item.get('title', 'Unknown')[:50]} - {e}")
                db.rollback()  # å›æ»šå½“å‰å¤±è´¥çš„äº‹åŠ¡
                continue
        
        logger.info(f"åŒæ­¥å®Œæˆï¼šæ–°å¢ {added_count} ä¸ªï¼Œæ›´æ–° {updated_count} ä¸ª")
        
        return SyncResponse(
            success=True,
            message=f"åŒæ­¥å®Œæˆï¼šæ–°å¢ {added_count} ä¸ªï¼Œæ›´æ–° {updated_count} ä¸ª",
            added_count=added_count,
            updated_count=updated_count
        )
    except Exception as e:
        db.rollback()
        raise HTTPException(status_code=500, detail=str(e))
    finally:
        crawler.close()

